{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4025082e",
   "metadata": {},
   "source": [
    "# Replicating DCT\n",
    "\n",
    "We try to replicate the results of *Deep Causal Transcoding (DCT)*.\n",
    "\n",
    "Test repo has been cloned within workspace and have space for model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0298cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.insert(0, \"/workspace/SPAR-causal-probes\")\n",
    "# import dct\n",
    "\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# model_name = \"Qwen/Qwen1.5-7B-Chat\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_name, device_map=\"auto\", torch_dtype=\"auto\", trust_remote_code=True\n",
    "# )\n",
    "\n",
    "# # Then follow the DCT demo pattern:\n",
    "# # 1. Create a SlicedModel\n",
    "# # 2. Set up DeltaActivations\n",
    "# # 3. Fit the DCT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803fbcfc",
   "metadata": {},
   "source": [
    "# Replicating `demo.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "id": "cft9ipuhc8e",
   "source": "import gc\nimport torch\n\n# Drop any variables from a previous run\nfor _var in [\"model\", \"tokenizer\", \"sliced_model\", \"delta_acts_single\", \"delta_acts\",\n             \"steering_calibrator\", \"exp_dct\", \"X\", \"Y\", \"U\", \"V\", \"hidden_states\"]:\n    if _var in dir():\n        del globals()[_var]\n\ngc.collect()\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\n    torch.cuda.synchronize()\n    print(f\"GPU memory allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n    print(f\"GPU memory reserved:  {torch.cuda.memory_reserved()   / 1e9:.2f} GB\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149ce26",
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.insert(0, \"/workspace/SPAR-causal-probes\")\nsys.modules.pop(\"dct\", None)  # evict any cached import so sys.path is re-searched\nimport dct\nfrom tqdm import tqdm\nimport math\nfrom torch import vmap\nimport torch\ntorch.set_default_device(\"cuda\")\ntorch.set_default_dtype(torch.bfloat16)\ntorch.manual_seed(325)"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen1.5-7B-Chat\"\n",
    "TOKENIZER_NAME = MODEL_NAME\n",
    "\n",
    "INPUT_SCALE = None          # norm of steering vectors; set to None to use default calibration\n",
    "\n",
    "NUM_SAMPLES = 1             # number of training samples\n",
    "FORWARD_BATCH_SIZE = 1      # batch size to use when computing forward passes\n",
    "BACKWARD_BATCH_SIZE = 1     # batch size to use when computing backward passes (usually smaller)\n",
    "MAX_SEQ_LEN = 27            # max length for truncating training examples\n",
    "\n",
    "CALIBRATION_SAMPLE_SIZE = 30        # sample size for random directions used to calibrate input/output scales\n",
    "CALIBRATION_PROMPT_SAMPLE_SIZE = 1  # prompt sample size for calibrating input scale\n",
    "\n",
    "DIM_OUTPUT_PROJECTION = 32 # output projection used for approximate jacobian calculation\n",
    "\n",
    "\n",
    "NUM_ITERS = 10               # number of iterations\n",
    "\n",
    "NUM_FACTORS = 512           # number of factors to learn\n",
    "FACTOR_BATCH_SIZE = 16      # factor batch size, reduced for this pod\n",
    "\n",
    "SOURCE_LAYER_IDX = 10       # source layer\n",
    "TARGET_LAYER_IDX = 20       # target layer\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a helpful assistant\" # system prompt; set to None for no system prompt\n",
    "\n",
    "TOKEN_IDXS = slice(-3,None) # target token positions\n",
    "\n",
    "NUM_EVAL = 128               # number of steering vectors to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cea29be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# will use beginning/end of this dataset for train/test prompts\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "url = 'https://raw.githubusercontent.com/llm-attacks/llm-attacks/main/data/advbench/harmful_behaviors.csv'\n",
    "response = requests.get(url)\n",
    "\n",
    "dataset = pd.read_csv(io.StringIO(response.content.decode('utf-8')))\n",
    "instructions = dataset['goal'].tolist()\n",
    "\n",
    "import random\n",
    "random.seed(325)\n",
    "#random.shuffle(instructions)\n",
    "if NUM_SAMPLES == 1:\n",
    "    instructions = [\"Tell me how to make a bomb.\"] + instructions\n",
    "\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_NAME, trust_remote_code=True, padding_side=\"left\",truncation_side=\"left\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "if SYSTEM_PROMPT is not None:\n",
    "    chat_init = [{'content':SYSTEM_PROMPT, 'role':'system'}]\n",
    "else:\n",
    "    chat_init = []\n",
    "chats = [chat_init + [{'content': content, 'role':'user'}] for content in instructions[:NUM_SAMPLES]]\n",
    "EXAMPLES = [tokenizer.apply_chat_template(chat, add_special_tokens=False, tokenize=False, add_generation_prompt=True) for chat in chats]\n",
    "\n",
    "test_chats = [chat_init + [{'content': content, 'role':'user'}] for content in instructions[-32:]]\n",
    "TEST_EXAMPLES = [tokenizer.apply_chat_template(chat, add_special_tokens=False, tokenize=False, add_generation_prompt=True) for chat in test_chats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1611c911",
   "metadata": {},
   "outputs": [],
   "source": "%%time\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nmodel = AutoModelForCausalLM.from_pretrained(MODEL_NAME,\n                                             trust_remote_code=True,\n                                             _attn_implementation=\"eager\", # currently, `torch.func` only works well with eager attention\n                                             torch_dtype=torch.bfloat16,\n                                            ).cuda()"
  },
  {
   "cell_type": "code",
   "id": "f9kul6eliu",
   "source": "print(f\"model.dtype:          {model.dtype}\")\nprint(f\"first param dtype:    {next(model.parameters()).dtype}\")\nprint(f\"layer 10 q_proj:      {model.model.layers[10].self_attn.q_proj.weight.dtype}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b715f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer([\"tell me how to make a bomb\"], return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "with torch.no_grad():\n",
    "    hidden_states = model(model_inputs[\"input_ids\"], output_hidden_states=True).hidden_states\n",
    "sliced_model =dct.SlicedModel(model, start_layer=3, end_layer=5, layers_name=\"model.layers\")\n",
    "with torch.no_grad():\n",
    "    assert torch.allclose(sliced_model(hidden_states[3]), hidden_states[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef9aefdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_model = dct.SlicedModel(model, start_layer=SOURCE_LAYER_IDX, end_layer=TARGET_LAYER_IDX, layers_name=\"model.layers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3fd780",
   "metadata": {},
   "outputs": [],
   "source": "d_model = model.config.hidden_size\n\nX = torch.zeros(NUM_SAMPLES, MAX_SEQ_LEN, d_model, device=\"cpu\", dtype=model.dtype)\nY = torch.zeros(NUM_SAMPLES, MAX_SEQ_LEN, d_model, device=\"cpu\", dtype=model.dtype)\nfor t in tqdm(range(0, NUM_SAMPLES, FORWARD_BATCH_SIZE)):\n    with torch.no_grad():\n        model_inputs = tokenizer(EXAMPLES[t:t+FORWARD_BATCH_SIZE], return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=MAX_SEQ_LEN).to(model.device)\n        hidden_states = model(model_inputs[\"input_ids\"], output_hidden_states=True).hidden_states\n        h_source = hidden_states[SOURCE_LAYER_IDX] # b x t x d_model\n        unsteered_target = sliced_model(h_source) # b x t x d_model\n\n        X[t:t+FORWARD_BATCH_SIZE, :, :] = h_source.cpu()\n        Y[t:t+FORWARD_BATCH_SIZE, :, :] = unsteered_target.cpu()"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da42a971",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_acts_single = dct.DeltaActivations(sliced_model, target_position_indices=TOKEN_IDXS) # d_model, batch_size x seq_len x d_model, batch_size x seq_len x d_model\n",
    "# -> batch_size x d_model\n",
    "delta_acts = vmap(delta_acts_single, in_dims=(1,None,None), out_dims=2,\n",
    "                  chunk_size=FACTOR_BATCH_SIZE) # d_model x num_factors -> batch_size x d_model x num_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e0c0388",
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_calibrator = dct.SteeringCalibrator(target_ratio=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b871a1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.51 s, sys: 837 ms, total: 2.35 s\n",
      "Wall time: 7.11 s\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot access data pointer of Tensor that doesn't have storage",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_cell_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mif INPUT_SCALE is None:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m    INPUT_SCALE = steering_calibrator.calibrate(delta_acts_single,X.cuda(),Y.cuda(),factor_batch_size=FACTOR_BATCH_SIZE)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2572\u001b[39m, in \u001b[36mInteractiveShell.run_cell_magic\u001b[39m\u001b[34m(self, magic_name, line, cell)\u001b[39m\n\u001b[32m   2570\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m   2571\u001b[39m     args = (magic_arg_s, cell)\n\u001b[32m-> \u001b[39m\u001b[32m2572\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2576\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2577\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:1447\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupt_occured:\n\u001b[32m   1446\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exit_on_interrupt \u001b[38;5;129;01mand\u001b[39;00m captured_exception:\n\u001b[32m-> \u001b[39m\u001b[32m1447\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m captured_exception\n\u001b[32m   1448\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1449\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/IPython/core/magics/execution.py:1411\u001b[39m, in \u001b[36mExecutionMagics.time\u001b[39m\u001b[34m(self, line, cell, local_ns)\u001b[39m\n\u001b[32m   1409\u001b[39m st = clock2()\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_ns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m     out = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;66;03m# multi-line %%time case\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<timed exec>:2\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/dct.py:150\u001b[39m, in \u001b[36mSteeringCalibrator.calibrate\u001b[39m\u001b[34m(self, delta_acts_single, X, Y, batch_size, calibration_sample_size, factor_batch_size)\u001b[39m\n\u001b[32m    148\u001b[39m         x = X[b:b+batch_size,:,:].to(delta_acts_single.device)\n\u001b[32m    149\u001b[39m         y = Y[b:b+batch_size,:,:].to(delta_acts_single.device)\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m         U_cal_batch = \u001b[43mjvp_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mV_cal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m         U_cal_avg.update(U_cal_batch)\n\u001b[32m    152\u001b[39m U_cal = U_cal_avg.get_mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/_functorch/apis.py:208\u001b[39m, in \u001b[36mvmap.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    207\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(*args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvmap_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/_functorch/vmap.py:272\u001b[39m, in \u001b[36mvmap_impl\u001b[39m\u001b[34m(func, in_dims, out_dims, randomness, chunk_size, *args, **kwargs)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunk_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    269\u001b[39m     chunks_flat_args = _get_chunked_inputs(\n\u001b[32m    270\u001b[39m         flat_args, flat_in_dims, batch_size, chunk_size\n\u001b[32m    271\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chunked_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m        \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunks_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[38;5;66;03m# If chunk_size is not specified.\u001b[39;00m\n\u001b[32m    283\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _flat_vmap(\n\u001b[32m    284\u001b[39m     func,\n\u001b[32m    285\u001b[39m     batch_size,\n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m     **kwargs,\n\u001b[32m    292\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/_functorch/vmap.py:384\u001b[39m, in \u001b[36m_chunked_vmap\u001b[39m\u001b[34m(func, flat_in_dims, chunks_flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[39m\n\u001b[32m    381\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m rs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    382\u001b[39m         torch.set_rng_state(rs)\n\u001b[32m    383\u001b[39m     chunks_output.append(\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m         \u001b[43m_flat_vmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m            \u001b[49m\u001b[43mflat_in_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m            \u001b[49m\u001b[43mflat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m            \u001b[49m\u001b[43margs_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m            \u001b[49m\u001b[43mout_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrandomness\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    394\u001b[39m     )\n\u001b[32m    396\u001b[39m flat_output_chunks, arg_spec = _flatten_chunks_output(chunks_output)\n\u001b[32m    398\u001b[39m \u001b[38;5;66;03m# chunked output tensors are held by both `flat_output_chunks` and `chunks_output`.\u001b[39;00m\n\u001b[32m    399\u001b[39m \u001b[38;5;66;03m# eagerly remove the reference from `chunks_output`.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/_functorch/vmap.py:433\u001b[39m, in \u001b[36m_flat_vmap\u001b[39m\u001b[34m(func, batch_size, flat_in_dims, flat_args, args_spec, out_dims, randomness, **kwargs)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m vmap_increment_nesting(batch_size, randomness) \u001b[38;5;28;01mas\u001b[39;00m vmap_level:\n\u001b[32m    430\u001b[39m     batched_inputs = _create_batched_inputs(\n\u001b[32m    431\u001b[39m         flat_in_dims, flat_args, vmap_level, args_spec\n\u001b[32m    432\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m     batched_outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mbatched_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _unwrap_batched(batched_outputs, out_dims, vmap_level, batch_size, func)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/dct.py:143\u001b[39m, in \u001b[36mSteeringCalibrator.calibrate.<locals>.<lambda>\u001b[39m\u001b[34m(v, X, Y)\u001b[39m\n\u001b[32m    141\u001b[39m     _, jvp_out = jvp(\u001b[38;5;28;01mlambda\u001b[39;00m _v: delta_acts_single(_v,X,Y), (v0,), (v,))\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m jvp_out\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m jvp_batch = vmap(\u001b[38;5;28;01mlambda\u001b[39;00m v, X, Y: \u001b[43mjvp_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m, in_dims=(\u001b[32m1\u001b[39m,\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[38;5;28;01mNone\u001b[39;00m), out_dims=(\u001b[32m2\u001b[39m), chunk_size=factor_batch_size)\n\u001b[32m    145\u001b[39m U_cal_avg = StreamingAverage()\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/dct.py:141\u001b[39m, in \u001b[36mSteeringCalibrator.calibrate.<locals>.jvp_single\u001b[39m\u001b[34m(v, X, Y)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mjvp_single\u001b[39m(v,X,Y):\n\u001b[32m    140\u001b[39m     v0 = torch.zeros_like(v)\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     _, jvp_out = \u001b[43mjvp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_v\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta_acts_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mv0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m jvp_out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1043\u001b[39m, in \u001b[36mjvp\u001b[39m\u001b[34m(func, primals, tangents, strict, has_aux)\u001b[39m\n\u001b[32m    984\u001b[39m \u001b[38;5;129m@exposed_in\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mtorch.func\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mjvp\u001b[39m(\n\u001b[32m    986\u001b[39m     func: Callable,\n\u001b[32m   (...)\u001b[39m\u001b[32m    991\u001b[39m     has_aux: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    992\u001b[39m ):\n\u001b[32m    993\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    994\u001b[39m \u001b[33;03m    Standing for the Jacobian-vector product, returns a tuple containing\u001b[39;00m\n\u001b[32m    995\u001b[39m \u001b[33;03m    the output of `func(*primals)` and the \"Jacobian of ``func`` evaluated at\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1040\u001b[39m \n\u001b[32m   1041\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_jvp_with_argnums\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtangents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margnums\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_aux\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/_functorch/eager_transforms.py:1102\u001b[39m, in \u001b[36m_jvp_with_argnums\u001b[39m\u001b[34m(func, primals, tangents, argnums, strict, has_aux)\u001b[39m\n\u001b[32m   1100\u001b[39m     primals = _wrap_all_tensors(primals, level)\n\u001b[32m   1101\u001b[39m     duals = _replace_args(primals, duals, argnums)\n\u001b[32m-> \u001b[39m\u001b[32m1102\u001b[39m result_duals = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mduals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_aux:\n\u001b[32m   1104\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(result_duals, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(result_duals) == \u001b[32m2\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/dct.py:141\u001b[39m, in \u001b[36mSteeringCalibrator.calibrate.<locals>.jvp_single.<locals>.<lambda>\u001b[39m\u001b[34m(_v)\u001b[39m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mjvp_single\u001b[39m(v,X,Y):\n\u001b[32m    140\u001b[39m     v0 = torch.zeros_like(v)\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     _, jvp_out = jvp(\u001b[38;5;28;01mlambda\u001b[39;00m _v: \u001b[43mdelta_acts_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m, (v0,), (v,))\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m jvp_out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/dct.py:74\u001b[39m, in \u001b[36mDeltaActivations.forward\u001b[39m\u001b[34m(self, theta, x, y)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, theta, x, y):\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    computes average delta in target layer activations as a \u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[33;03m    function of bias theta\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[33;03m    '''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     delta = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msliced_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m+\u001b[49m\u001b[43mtheta\u001b[49m\u001b[43m)\u001b[49m - y \u001b[38;5;66;03m# batch_size x seq_len x d_model\u001b[39;00m\n\u001b[32m     75\u001b[39m     delta = delta[:, \u001b[38;5;28mself\u001b[39m.target_position_indices, :]\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m delta.mean(dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/dct.py:57\u001b[39m, in \u001b[36mSlicedModel.forward\u001b[39m\u001b[34m(self, h)\u001b[39m\n\u001b[32m     54\u001b[39m     rgetattr(\u001b[38;5;28mself\u001b[39m.model, \u001b[38;5;28mself\u001b[39m.layers_name)[i].self_attn.layer_idx = i\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# actually run the forward pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.hidden_states[\u001b[38;5;28mself\u001b[39m.end_layer-\u001b[38;5;28mself\u001b[39m.start_layer]\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# reset model to un-mutated state\u001b[39;00m\n\u001b[32m     60\u001b[39m \u001b[38;5;28mself\u001b[39m.reset()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/accelerate/hooks.py:175\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    173\u001b[39m         output = module._old_forward(*args, **kwargs)\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     output = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m module._hf_hook.post_forward(module, output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:1164\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, num_logits_to_keep, **loss_kwargs)\u001b[39m\n\u001b[32m   1161\u001b[39m return_dict = return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.use_return_dict\n\u001b[32m   1163\u001b[39m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1164\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1172\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1173\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1174\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1175\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1177\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1178\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/transformers/models/qwen2/modeling_qwen2.py:914\u001b[39m, in \u001b[36mQwen2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    911\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n\u001b[32m    912\u001b[39m         all_self_attns += (layer_outputs[\u001b[32m1\u001b[39m],)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[38;5;66;03m# add hidden states from the last decoder layer\u001b[39;00m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1776\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1775\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1776\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1787\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1786\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1787\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1789\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/accelerate/hooks.py:170\u001b[39m, in \u001b[36madd_hook_to_module.<locals>.new_forward\u001b[39m\u001b[34m(module, *args, **kwargs)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnew_forward\u001b[39m(module, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     args, kwargs = \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_hf_hook\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpre_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m module._hf_hook.no_grad:\n\u001b[32m    172\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/accelerate/hooks.py:360\u001b[39m, in \u001b[36mAlignDevicesHook.pre_forward\u001b[39m\u001b[34m(self, module, *args, **kwargs)\u001b[39m\n\u001b[32m    352\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    353\u001b[39m             value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    354\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    355\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m value.data_ptr() \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map\n\u001b[32m    356\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.execution_device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tied_params_map[value.data_ptr()]\n\u001b[32m    357\u001b[39m         ):\n\u001b[32m    358\u001b[39m             \u001b[38;5;28mself\u001b[39m.tied_pointers_to_remove.add((value.data_ptr(), \u001b[38;5;28mself\u001b[39m.execution_device))\n\u001b[32m--> \u001b[39m\u001b[32m360\u001b[39m         \u001b[43mset_module_tensor_to_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m            \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecution_device\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m            \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfp16_statistics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtied_params_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m send_to_device(args, \u001b[38;5;28mself\u001b[39m.execution_device), send_to_device(\n\u001b[32m    370\u001b[39m     kwargs, \u001b[38;5;28mself\u001b[39m.execution_device, skip_keys=\u001b[38;5;28mself\u001b[39m.skip_keys\n\u001b[32m    371\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspace/SPAR-causal-probes/.venv/lib/python3.12/site-packages/accelerate/utils/modeling.py:421\u001b[39m, in \u001b[36mset_module_tensor_to_device\u001b[39m\u001b[34m(module, tensor_name, device, value, dtype, fp16_statistics, tied_params_map, non_blocking, clear_cache)\u001b[39m\n\u001b[32m    412\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    413\u001b[39m     tied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    414\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m old_value.data_ptr() \u001b[38;5;129;01min\u001b[39;00m tied_params_map\n\u001b[32m    415\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tied_params_map[old_value.data_ptr()]\n\u001b[32m    416\u001b[39m ):\n\u001b[32m    417\u001b[39m     tied_params_map[old_value.data_ptr()][device] = new_value\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[32m    419\u001b[39m     value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    420\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m tied_params_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_ptr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01min\u001b[39;00m tied_params_map\n\u001b[32m    422\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m device \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m tied_params_map[value.data_ptr()]\n\u001b[32m    423\u001b[39m ):\n\u001b[32m    424\u001b[39m     tied_params_map[value.data_ptr()][device] = new_value\n",
      "\u001b[31mRuntimeError\u001b[39m: Cannot access data pointer of Tensor that doesn't have storage"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if INPUT_SCALE is None:\n",
    "    INPUT_SCALE = steering_calibrator.calibrate(delta_acts_single,X.cuda(),Y.cuda(),factor_batch_size=FACTOR_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49397a3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.883877155052653\n"
     ]
    }
   ],
   "source": [
    "print(INPUT_SCALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae0833b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing jacobian...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [01:09<00:00, 69.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing SVD of jacobian...\n",
      "computing output directions...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "exp_dct= dct.ExponentialDCT(num_factors=NUM_FACTORS)\n",
    "U,V = exp_dct.fit(delta_acts_single, X, Y, batch_size=BACKWARD_BATCH_SIZE, factor_batch_size=FACTOR_BATCH_SIZE,\n",
    "            init=\"jacobian\", d_proj=DIM_OUTPUT_PROJECTION, input_scale=INPUT_SCALE, max_iters=10, beta=1.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spar-causal-probes (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}